{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Audio Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note on Data Locations \n",
    "\n",
    "I recommend putting the audio (WAV) and image (PNG) files in `data\\audio` and `data\\iamges` directories, respectively.\n",
    "\n",
    "The `data\\` directory is already included in the `.gitignore` file, and so these large binary files won't be included in commits.\n",
    "\n",
    "**Example:**\n",
    "\n",
    "<img src=\"data_structure_example.png\" style=\"widht:400px; height:auto;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "from IPython.display import Audio\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Audio Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AudioFile class\n",
    "\n",
    "- `file_path`: Path to the audio file\n",
    "- `file_name`: Name of the audio file (extracted from the path)\n",
    "- `label`: Label of the audio file (derived from the parent directory name)\n",
    "- `audio`: Loaded audio data\n",
    "- `sample_rate`: Sampling rate of the audio file\n",
    "- `duration`: Duration of the audio file in seconds\n",
    "\n",
    "#### Methods\n",
    "\n",
    "- `display_waveform()`: Display the waveform of the audio file\n",
    "- `play()`: Play the audio file and return an audio player widget\n",
    "- `trim(top_db=30)`: Trim silent parts of the audio using a decibel threshold\n",
    "- `create_spectrogram()`: Generate a mel spectrogram of the audio file\n",
    "- `show_spectrogram()`: Display the spectrogram of the audio file\n",
    "- `save_spectrogram(output_dir=None, skip_existing=True)`: Save the spectrogram as a PNG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioFile:\n",
    "    \"\"\"\n",
    "    A class to handle audio files and provide utilities for analysis and visualization.\n",
    "\n",
    "    Attributes:\n",
    "        file_path (str): Path to the audio file.\n",
    "        file_name (str): Name of the audio file (extracted from the path).\n",
    "        label (str): Label of the audio file (derived from the parent directory name).\n",
    "        audio (np.ndarray): Loaded audio data.\n",
    "        sample_rate (int): Sampling rate of the audio file.\n",
    "        duration (float): Duration of the audio file in seconds.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Initialize the AudioFile instance by loading the audio file and extracting metadata.\n",
    "\n",
    "        Args:\n",
    "            file_path (str): Path to the audio file.\n",
    "        \"\"\"\n",
    "        self.file_path = file_path\n",
    "        self.file_name = os.path.basename(file_path)\n",
    "        self.label = os.path.basename(os.path.dirname(self.file_path))\n",
    "        self.audio, self.sample_rate = librosa.load(file_path)\n",
    "        self.duration = librosa.get_duration(y=self.audio, sr=self.sample_rate)\n",
    "\n",
    "    def display_waveform(self):\n",
    "        \"\"\"\n",
    "        Display the waveform of the audio file.\n",
    "        \"\"\"\n",
    "        librosa.display.waveshow(self.audio, sr=self.sample_rate)\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def play(self):\n",
    "        \"\"\"\n",
    "        Play the audio file.\n",
    "\n",
    "        Returns:\n",
    "            IPython.display.Audio: audio player widget.\n",
    "        \"\"\"\n",
    "        return Audio(self.file_path)\n",
    "\n",
    "    def trim(self, top_db=30):\n",
    "        \"\"\"\n",
    "        Trim silent parts of the audio based on a decibel threshold.\n",
    "\n",
    "        Args:\n",
    "            top_db (int, optional): Decibel threshold below which audio is considered silent. Defaults to 30.\n",
    "        \"\"\"\n",
    "        self.audio, _ = librosa.effects.trim(self.audio, top_db=top_db)\n",
    "\n",
    "    def create_spectrogram(self):\n",
    "        \"\"\"\n",
    "        Create a mel spectrogram of the audio file.\n",
    "\n",
    "        Returns:\n",
    "            np.ndarray: The mel spectrogram in decibel units.\n",
    "        \"\"\"\n",
    "        mel_scale_sgram = librosa.feature.melspectrogram(y=self.audio, sr=self.sample_rate, power=1)\n",
    "        mel_sgram = librosa.amplitude_to_db(mel_scale_sgram, ref=np.min)\n",
    "        return mel_sgram\n",
    "\n",
    "    def show_spectrogram(self):\n",
    "        \"\"\"\n",
    "        Display the spectrogram of the audio file.\n",
    "        \"\"\"\n",
    "        _spectrogram = self.create_spectrogram()\n",
    "        librosa.display.specshow(_spectrogram, sr=self.sample_rate, x_axis='time', y_axis='mel')\n",
    "        plt.colorbar(format='%+2.0f dB')\n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "    def save_spectrogram(self, output_dir=None, skip_existing=True):\n",
    "        \"\"\"\n",
    "        Save the spectrogram as a PNG file.\n",
    "\n",
    "        Args:\n",
    "            output_dir (str, optional): Directory to save the spectrogram. Defaults to the directory of the audio file.\n",
    "            skip_existing (bool, optional): Whether to skip saving if the file already exists. Defaults to True.\n",
    "        \"\"\"\n",
    "        if not output_dir:\n",
    "            output_dir = os.path.dirname(self.file_path)\n",
    "        else:\n",
    "            output_dir = os.path.join(output_dir, self.label)\n",
    "\n",
    "        _base, _ = os.path.splitext(self.file_name)\n",
    "        output_file = os.path.join(output_dir, _base + \".png\")\n",
    "\n",
    "        if skip_existing and os.path.exists(output_file):\n",
    "            return\n",
    "\n",
    "        _spectrogram = self.create_spectrogram()\n",
    "        librosa.display.specshow(_spectrogram, sr=self.sample_rate)\n",
    "\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        plt.savefig(output_file)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example of using AudioFile Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_audio_file = os.path.join(\"data\", \"audio\", \"Speech Commands\", \"backward\", \"0a2b400e_nohash_0.wav\")\n",
    "test_audio = AudioFile(_audio_file)\n",
    "\n",
    "test_audio.display_waveform()\n",
    "test_audio.show_spectrogram()\n",
    "test_audio.trim()\n",
    "test_audio.display_waveform()\n",
    "test_audio.show_spectrogram()\n",
    "test_audio.play()   # NOTE: play() has to be in its own cell or the last line; otherwise it doesn't show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Audio Files to Spectrograms "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Audio Files to Spectrograms \n",
    "\n",
    " - set input_dir and output_dir accordingly\n",
    " - call process_directory()\n",
    " - if skip_existing is True, existing spectrogram PNG files will be skipped (recommended)\n",
    "\n",
    "\n",
    "### NOTE:\n",
    "\n",
    "- Only run this cell if you need to save out all the spectrograms. It takes awhile, and is prone to crashing (hence the use of skip_existing, so it can continue where it left off).\n",
    "- Commented out the \"process_directory(...)\" line at the bottom to avoid accidental runs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = os.path.join(\"data\", \"audio\",\"Speech Commands\")\n",
    "output_dir = os.path.join(\"data\", \"images\", \"Speech Commands\")\n",
    "\n",
    "def process_directory(input_dir, output_dir, skip_existing=True):\n",
    "    for root, dirs, files in os.walk(input_dir):\n",
    "        # sort directories alphabetically\n",
    "        dirs.sort()\n",
    "        print(f\"Processing directory: {os.path.basename(root)}\")\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                # load file\n",
    "                audio = AudioFile(os.path.join(root, file))\n",
    "                # save spectrogram\n",
    "                audio.save_spectrogram(output_dir, skip_existing=skip_existing)\n",
    "\n",
    "\n",
    "# process_directory(input_dir, output_dir, skip_existing=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "data_folder='data/audio/Speech Commands'\n",
    "files = [f for f in os.listdir(data_folder) if f != '.DS_Store'] #removes hidden files on Macs\n",
    "pd.DataFrame(files,columns=['Files']).sort_values(by='Files', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count(path):\n",
    "    size = []\n",
    "    folders = [folder for folder in os.listdir(path) if folder != '.DS_Store']\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        files = [file for file in os.listdir(folder_path) if file != '.DS_Store']  # Filter inside subdirectories\n",
    "        size.append(len(files))\n",
    "    return pd.DataFrame(size,columns=['Number Of Sample'],index=folders)  \n",
    "    \n",
    "file_counts = count(data_folder)\n",
    "print(\"File Counts:\", f\"file_counts\")\n",
    "file_counts.sort_values(by='Number Of Sample', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create time series dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(path):\n",
    "    file_paths = []\n",
    "    data = []\n",
    "    label = []\n",
    "    sample = []\n",
    "    durations = []\n",
    "    folders = [folder for folder in os.listdir(path) if folder != '.DS_Store']\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(path, folder)\n",
    "        if os.listdir(folder_path):\n",
    "            files = [file for file in os.listdir(folder_path) if file != '.DS_Store']\n",
    "            for fil in files:\n",
    "                file_path = os.path.join(folder_path,fil)\n",
    "                audio_file = AudioFile(file_path)\n",
    "                audio_data = audio_file.audio\n",
    "                sample_rate = audio_file.sample_rate\n",
    "                duration = audio_file.duration\n",
    "                file_paths.append(file_path)\n",
    "                data.append(audio_data)\n",
    "                sample.append(sample_rate)\n",
    "                label.append(folder)\n",
    "                durations.append(duration)\n",
    "    return data,file_paths,label,sample,durations\n",
    "\n",
    "audio_data,file_paths,label,sample,durations = create_dataset(data_folder)\n",
    "audio_df = pd.DataFrame()\n",
    "audio_df['file_paths'], audio_df['Label'], audio_df['sample'], audio_df['duration'] = file_paths,label,sample,durations\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Numbered Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbered_labels = {}\n",
    "start = 0\n",
    "for i in pd.unique(audio_df.Label):\n",
    "    numbered_labels[i] = start\n",
    "    start += 1\n",
    "\n",
    "pd.DataFrame(numbered_labels.values(),columns=['Value'],index=numbered_labels.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label data with numbered labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_df['Numbered Label'] = audio_df['Label'].apply(lambda x: numbered_labels[x]) \n",
    "\n",
    "audio_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the arrays so they are all the same length\n",
    "audio_data_padded = [\n",
    "    np.pad(arr, (0, 22050 - len(arr)), mode='constant', constant_values=0)\n",
    "    for arr in audio_data]\n",
    "\n",
    "# Create array from list of data arrays\n",
    "audio_data_arr = np.array(audio_data_padded)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
